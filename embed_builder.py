"""
embed_builder.py
PDF dosyalarÄ±ndan FAISS vektÃ¶r indeksi oluÅŸturur.
"""

import os
import glob
from tqdm import tqdm
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

# ===============================
# CONFIGURATION
# ===============================
PDF_FOLDER = "./docs"
EMBEDDING_MODEL = "BAAI/bge-m3"
INDEX_PATH = "embeddings/faiss_index"

# Chunk settings
CHUNK_SIZE = 1000
CHUNK_OVERLAP = 200
SEPARATORS = ["\n\n", "\n", ".", " ", ""]

# Batch size for embedding (daha kÃ¼Ã§Ã¼k yaparsanÄ±z daha sÄ±k gÃ¼ncelleme gÃ¶rÃ¼rsÃ¼nÃ¼z)
BATCH_SIZE = 16  # 32'den 16'ya dÃ¼ÅŸÃ¼rdÃ¼m, daha sÄ±k progress gÃ¶rÃ¼lsÃ¼n


def load_pdfs(folder_path: str) -> list:
    """KlasÃ¶rdeki tÃ¼m PDF dosyalarÄ±nÄ± yÃ¼kler."""
    pdf_files = glob.glob(os.path.join(folder_path, "*.pdf"))
    
    if not pdf_files:
        raise FileNotFoundError(f"'{folder_path}' klasÃ¶rÃ¼nde PDF dosyasÄ± bulunamadÄ±!")
    
    print(f"\n{'='*60}")
    print(f"ğŸ“ {len(pdf_files)} PDF dosyasÄ± bulundu:")
    for pdf in pdf_files:
        print(f"   â€¢ {os.path.basename(pdf)}")
    print(f"{'='*60}\n")
    
    all_texts = []
    failed_files = []
    
    for file in tqdm(pdf_files, desc="ğŸ“„ PDF'ler yÃ¼kleniyor", unit="dosya"):
        try:
            loader = PyPDFLoader(file)
            docs = loader.load()
            all_texts.extend(docs)
        except Exception as e:
            failed_files.append((os.path.basename(file), str(e)))
    
    if failed_files:
        print(f"\nâš ï¸  {len(failed_files)} dosya yÃ¼klenemedi:")
        for filename, error in failed_files:
            print(f"   âœ— {filename}: {error}")
    
    print(f"\nâœ… Toplam {len(all_texts)} sayfa baÅŸarÄ±yla yÃ¼klendi.\n")
    return all_texts


def create_chunks(documents: list, chunk_size: int = CHUNK_SIZE, 
                  chunk_overlap: int = CHUNK_OVERLAP) -> list:
    """DÃ¶kÃ¼manlarÄ± RAG iÃ§in optimize edilmiÅŸ chunk'lara bÃ¶ler."""
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len,
        separators=SEPARATORS,
        add_start_index=True,
    )
    
    chunks = splitter.split_documents(documents)
    
    print(f"{'='*60}")
    print(f"âœ‚ï¸  CHUNKING SONUÃ‡LARI:")
    print(f"   â€¢ Toplam chunk: {len(chunks)}")
    print(f"   â€¢ Chunk boyutu: {chunk_size} karakter")
    print(f"   â€¢ Overlap: {chunk_overlap} karakter")
    print(f"{'='*60}\n")
    
    if chunks:
        print("ğŸ“ Ã–rnek Chunk:")
        print("-" * 60)
        print(f"Kaynak: {chunks[0].metadata.get('source', 'N/A')}")
        print(f"Sayfa: {chunks[0].metadata.get('page', 'N/A')}")
        print(f"\nÄ°Ã§erik (ilk 300 karakter):")
        print(chunks[0].page_content[:300] + "...\n")
        print("-" * 60 + "\n")
    
    return chunks


def build_vector_store_with_progress(chunks: list, model_name: str = EMBEDDING_MODEL, 
                                     index_path: str = INDEX_PATH,
                                     batch_size: int = BATCH_SIZE) -> FAISS:
    """
    Embedding modeli ile FAISS vektÃ¶r deposu oluÅŸturur - Progress bar ile!
    
    Args:
        chunks: Embedding yapÄ±lacak chunk'lar
        model_name: KullanÄ±lacak embedding modeli
        index_path: Ä°ndeksin kaydedileceÄŸi yol
        batch_size: Her batch'te kaÃ§ chunk iÅŸlenecek
        
    Returns:
        FAISS: OluÅŸturulan vektÃ¶r deposu
    """
    print(f"{'='*60}")
    print(f"ğŸ¤– EMBEDDING MODELÄ° YÃœKLENÄ°YOR...")
    print(f"   Model: {model_name}")
    print(f"{'='*60}\n")
    
    try:
        # Embedding modelini yÃ¼kle
        embedding_model = HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs={'device': 'cpu'},
            encode_kwargs={
                'normalize_embeddings': True,
                'batch_size': batch_size,
            }
        )
        
        print(f"ğŸ”„ EMBEDDING Ä°ÅLEMÄ° BAÅLIYOR...")
        print(f"   â€¢ Toplam chunk: {len(chunks)}")
        print(f"   â€¢ Batch boyutu: {batch_size}")
        print(f"   â€¢ Tahmini batch sayÄ±sÄ±: {(len(chunks) + batch_size - 1) // batch_size}\n")
        
        # Batch'ler halinde embedding yap
        vectorstore = None
        
        for i in tqdm(range(0, len(chunks), batch_size), 
                     desc="ğŸ§® Embedding yapÄ±lÄ±yor",
                     unit="batch",
                     bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'):
            
            batch = chunks[i:i + batch_size]
            
            if vectorstore is None:
                # Ä°lk batch - yeni vectorstore oluÅŸtur
                vectorstore = FAISS.from_documents(batch, embedding_model)
            else:
                # Sonraki batch'ler - mevcut vectorstore'a ekle
                batch_vectorstore = FAISS.from_documents(batch, embedding_model)
                vectorstore.merge_from(batch_vectorstore)
        
        print(f"\nâœ… Embedding tamamlandÄ±!\n")
        
        # Ä°ndeksi kaydet
        print("ğŸ’¾ Ä°ndeks kaydediliyor...")
        os.makedirs(os.path.dirname(index_path), exist_ok=True)
        vectorstore.save_local(index_path)
        
        print(f"\n{'='*60}")
        print(f"âœ… BAÅARILI!")
        print(f"   â€¢ Ä°ndeks konumu: {index_path}")
        print(f"   â€¢ Toplam vektÃ¶r: {vectorstore.index.ntotal}")
        print(f"   â€¢ VektÃ¶r boyutu: {vectorstore.index.d}")
        print(f"   â€¢ Dosya boyutu: {get_folder_size(index_path):.2f} MB")
        print(f"{'='*60}\n")
        
        return vectorstore
        
    except Exception as e:
        print(f"\nâŒ EMBEDDING HATASI: {e}")
        raise


def get_folder_size(folder_path: str) -> float:
    """KlasÃ¶r boyutunu MB cinsinden dÃ¶ndÃ¼rÃ¼r"""
    total_size = 0
    try:
        for dirpath, dirnames, filenames in os.walk(folder_path):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                total_size += os.path.getsize(filepath)
        return total_size / (1024 * 1024)  # MB'ye Ã§evir
    except:
        return 0.0


def main():
    """Ana fonksiyon - tÃ¼m pipeline'Ä± Ã§alÄ±ÅŸtÄ±rÄ±r"""
    print("\n" + "="*60)
    print("ğŸš€ HUAWEI CLOUD RAG - VEKTÃ–R Ä°NDEKSÄ° OLUÅTURMA")
    print("="*60 + "\n")
    
    try:
        # 1. PDF'leri yÃ¼kle
        documents = load_pdfs(PDF_FOLDER)
        
        # 2. Chunk'lara bÃ¶l
        chunks = create_chunks(documents)
        
        # 3. FAISS vektÃ¶r deposu oluÅŸtur (Progress bar ile!)
        vectorstore = build_vector_store_with_progress(chunks)
        
        print("\n" + "="*60)
        print("ğŸ‰ Ä°ÅLEM TAMAMLANDI!")
        print("="*60)
        print(f"\nÅimdi 'rag_query.py' ile sorgu yapabilirsiniz.\n")
        
    except Exception as e:
        print(f"\nâŒ HATA: {e}\n")
        raise


if __name__ == "__main__":
    main()